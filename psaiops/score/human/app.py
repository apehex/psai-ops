import copy
import functools

import gradio
import numpy
import torch
import torch.cuda
import matplotlib.pyplot

import psaiops.common.model
import psaiops.common.style
import psaiops.common.tokenizer
import psaiops.score.human.lib

# META #########################################################################

MODEL = 'openai/gpt-oss-20b'

TITLE = '''Human Score'''
INTRO = '''Leverages an open source LLM as critic to take apart the sections written by a human from the text generated by an AI.\nThe final probability score is a combination of several metrics computed token by token.\nThe accuracy of the scores increases with the prompt length and the size of the window.\n\nSee the tab "docs" for more informations, in particular the formulas of the computations.'''
DOCS = '''The model used as critic is `openai/gpt-oss-20b`.'''

# overview
# samples
# combination = conflation
# assumptions:
# - open source LLM = good proxy for proprietary LLM
# - the context is embedded in the tail end of longer prompts
# limits:
# - only gpt-oss-20b available
# metrics:
# - llm ranks
# - perplexity
# - vocabulary
# plots:
# - raw vs prob

# ENUMS ########################################################################

# metric types
TOKENS = 1
CRITIC = 2
SAMPLING = 4

# COLORS #######################################################################

def create_selection_cmap() -> dict:
    return {
        '0': '#000000',
        '1': '#004444',
        '2': '#444400',
        '3': '#440044',}

def create_score_cmap() -> dict:
    return {
        str(__i): '#{:02x}{:02x}00'.format(
            int(2.55 * 2 * max(0, 50 - __i)), # red: decreasing prob of LLM from 0 to 50
            int(2.55 * 2 * max(0, __i - 50))) # green: increasing prob of human from 50 to 100
        for __i in range(101)}

# INTRO ########################################################################

def create_text_block(text: str) -> dict:
    __text = gradio.Markdown(text, line_breaks=True)
    return {'text_block': __text}

# MODEL ########################################################################

def create_model_block() -> dict:
    __model = gradio.Dropdown(label='Model', value='openai/gpt-oss-20b', choices=['openai/gpt-oss-20b'], scale=1, allow_custom_value=False, multiselect=False, interactive=True) # 'openai/gpt-oss-120b'
    return {'model_block': __model,}

# SAMPLING #####################################################################

def create_sampling_block() -> dict:
    __tokens = gradio.Slider(label='Tokens', value=32, minimum=1, maximum=256, step=1, scale=1, interactive=True)
    __topk = gradio.Slider(label='Top K', value=16, minimum=1, maximum=2048, step=1, scale=1, interactive=True)
    __topp = gradio.Slider(label='Top P', value=0.9, minimum=0.0, maximum=1.0, step=0.01, scale=1, interactive=True)
    return {
        'tokens_block': __tokens,
        'topk_block': __topk,
        'topp_block': __topp,}

# INPUTS #######################################################################

def create_inputs_block(label: str='Prompt', prefix: str='') -> dict:
    __input = gradio.Textbox(label=label, value='', placeholder='A string of tokens to score.', lines=4, scale=1, interactive=True)
    return {prefix + 'input_block': __input}

# PLOTS ########################################################################

def create_plot_block(label: str='Plot', prefix: str='') -> dict:
    __plot = gradio.Plot(label=label, scale=1)
    return {prefix + 'plot_block': __plot,}

# HIGHLIGHT ####################################################################

def create_highlight_block(label: str='Score', prefix: str='', cmap: dict=create_selection_cmap()) -> dict:
    __highlight = gradio.HighlightedText(label=label, value='', scale=1, interactive=False, show_legend=False, show_inline_category=False, combine_adjacent=False, color_map=cmap, elem_classes='white-text')
    return {prefix + 'highlight_block': __highlight}

# REDUCTION ####################################################################

def create_metrics_block(label: str='Metrics', prefix: str='') -> dict:
    __metrics = gradio.CheckboxGroup(label=label, type='value', value=[CRITIC, TOKENS], choices=[('Critic', CRITIC), ('Tokens', TOKENS)], interactive=True)
    return {prefix + 'metric_block': __metrics,}

def create_window_block(label: str='Window', prefix: str='') -> dict:
    __window = gradio.Slider(label=label, value=5, minimum=1, maximum=32, step=1, scale=1, interactive=True)
    return {prefix + 'window_block': __window,}

# ACTIONS ######################################################################

def create_actions_block() -> dict:
    __process = gradio.Button('Score', variant='primary', size='lg', scale=1, interactive=True)
    return {'process_block': __process,}

# STATE ########################################################################

def create_state() -> dict:
    return {
        'indices_state': gradio.State(None),
        'logits_state': gradio.State(None),}

# LAYOUT #######################################################################

def create_layout(intro: str=INTRO, docs: str=DOCS) -> dict:
    __fields = {}
    __fields.update(create_text_block(text=intro))
    with gradio.Tabs():
        with gradio.Tab('Scores') as __main_tab:
            __fields.update({'main_tab': __main_tab})
            with gradio.Row(equal_height=True):
                __fields.update(create_inputs_block(label='Prompt', prefix=''))
            with gradio.Row(equal_height=True):
                __fields.update(create_highlight_block(label='By Token', prefix='', cmap=create_score_cmap()))
            with gradio.Row(equal_height=True):
                __fields.update(create_plot_block(label='By Position', prefix=''))
            with gradio.Row(equal_height=True):
                __fields.update(create_metrics_block(label='Metrics', prefix=''))
                __fields.update(create_window_block(label='Window', prefix=''))
            with gradio.Row(equal_height=True):
                __fields.update(create_actions_block())
        with gradio.Tab('Settings') as __settings_tab:
            __fields.update({'settings_tab': __settings_tab})
            with gradio.Row(equal_height=True):
                __fields.update(create_model_block())
            with gradio.Row(equal_height=True):
                __fields.update(create_sampling_block())
        with gradio.Tab('Docs') as __docs_tab:
            __fields.update({'docs_tab': __docs_tab})
            __fields.update(create_text_block(text=docs))
    return __fields

# WINDOW #######################################################################

def update_window_range(
    current_val: float,
    indices_arr: object,
) -> dict:
    # exit if some values are missing
    if (current_val is None) or (indices_arr is None) or (len(indices_arr) == 0):
        return gradio.update()
    # take the generated tokens into account
    __max = max(1, int(indices_arr.shape[-1]))
    # keep the previous value if possible
    __val = min(int(current_val), __max)
    # return a gradio update dictionary
    return gradio.update(value=__val, maximum=__max)

# TOKENS #######################################################################

def update_indices_state(
    prompt_str: str,
    tokenizer_obj: object,
) -> object:
    # exit if some values are missing
    if (prompt_str is None) or (tokenizer_obj is None):
        return None
    # dictionary {'input_ids': _, 'attention_mask': _}
    __input_data = psaiops.common.tokenizer.preprocess_token_ids(
        tokenizer_obj=tokenizer_obj,
        prompt_str=prompt_str.strip(),
        device_str='cpu')
    # discard the mask, which is all ones
    return __input_data['input_ids'].cpu()

# LOGITS #######################################################################

def update_logits_state(
    indices_arr: object,
    model_obj: object,
) -> object:
    # exit if some values are missing
    if (indices_arr is None) or (model_obj is None):
        return None
    # move the output back to the CPU
    return psaiops.score.human.lib.compute_raw_logits(
        indices_arr=indices_arr.to(device=model_obj.device),
        model_obj=model_obj).cpu()

# RANK #########################################################################

def update_human_scores(
    indices_arr: object,
    logits_arr: object,
    tokenizer_obj: object,
) -> list:
    # exit if some values are missing
    if (indices_arr is None) or (len(indices_arr) == 0) or (logits_arr is None) or (len(logits_arr) == 0):
        return None
    # detokenize the IDs
    __token_str = psaiops.common.tokenizer.postprocess_token_ids(
        token_arr=indices_arr,
        tokenizer_obj=tokenizer_obj)
    # compute the rank metric, in [0.5; 1]
    __token_cls = psaiops.score.human.lib.compute_rank_metrics(
        indices_arr=indices_arr,
        logits_arr=logits_arr)
    # scale into a [0; 100] label
    __token_cls = psaiops.score.human.lib.postprocess_score_cls(
        score_arr=__token_cls,
        scale_val=100.0)
    # pad with neutral class 50 (1/2 chance LLM / human) for the tokens which have no logit (IE the first token)
    __token_cls = max(0, len(__token_str) - len(__token_cls)) * ['50'] + __token_cls
    # color each token according to its rank in the LLM's predictions
    return list(zip(__token_str, __token_cls))

def update_human_plots(
    indices_arr: object,
    logits_arr: object,
    window_dim: float,
) -> object:
    # exit if some values are missing
    if (window_dim is None) or (indices_arr is None) or (len(indices_arr) == 0) or (logits_arr is None) or (len(logits_arr) == 0):
        return None
    # compute the rank metric, in [0.5; 1]
    __yr = psaiops.score.human.lib.compute_rank_metrics(
        indices_arr=indices_arr,
        logits_arr=logits_arr,
        scope_dim=int(window_dim))
    # compute the entropy metric
    __ye = psaiops.score.human.lib.compute_entropy_metrics(
        logits_arr=logits_arr,
        scope_dim=int(window_dim))
    # compute the perplexity metric
    __yp = psaiops.score.human.lib.compute_perplexity_metrics(
        indices_arr=indices_arr,
        logits_arr=logits_arr,
        scope_dim=int(window_dim))
    # remove the batch axis
    __yr = __yr.squeeze(dim=0).numpy().tolist()
    __ye = __ye.squeeze(dim=0).numpy().tolist()
    __yp = __yp.squeeze(dim=0).numpy().tolist()
    # add the missing score for the first token
    __yr = [0.5] + __yr
    __ye = [0.5] + __ye
    __yp = [0.5] + __yp
    # rescale as a percentage like the token labels
    __yr = [int(100.0 * __s) for __s in __yr]
    __ye = [int(100.0 * __s) for __s in __ye]
    __yp = [int(100.0 * __s) for __s in __yp]
    # match the metrics with their token position
    __x = range(len(__yr))
    # plot the first sample
    __figure = matplotlib.pyplot.figure(figsize=(16, 4), dpi=120)
    __axes = __figure.add_subplot(1, 1, 1)
    __axes.plot(__x, __yr, linestyle='--', label='rank')
    __axes.plot(__x, __ye, linestyle='--', label='entropy')
    __axes.plot(__x, __yp, linestyle='--', label='perplexity')
    # display the legend and remove the extra padding
    __axes.legend()
    __figure.tight_layout()
    # remove the figure for the pyplot register for garbage collection
    matplotlib.pyplot.close(__figure)
    # update each component => (highlight, plot) states
    return __figure

# APP ##########################################################################

def create_app(
    tokenize: callable,
    compute: callable,
    score: callable,
    title: str=TITLE,
    intro: str=INTRO
) -> gradio.Blocks:
    __fields = {}
    with gradio.Blocks(title=title) as __app:
        # create the UI
        __fields.update(create_layout(intro=intro))
        # init the state
        __fields.update(create_state())
        # first tokenize to get the token indices
        __fields['process_block'].click(
            fn=tokenize,
            inputs=__fields['input_block'],
            outputs=__fields['indices_state'],
            queue=False,
            show_progress='hidden'
        ).then(
        # then compute the associated logits
            fn=compute,
            inputs=__fields['indices_state'],
            outputs=__fields['logits_state'],
            queue=False,
            show_progress='hidden'
        ).then(
        # then compute the scores
            fn=score,
            inputs=[__fields[__k] for __k in ['indices_state', 'logits_state']],
            outputs=__fields['highlight_block'],
            queue=False,
            show_progress='full'
        ).then(
        # and plot the metrics
            fn=update_human_plots,
            inputs=[__fields[__k] for __k in ['indices_state', 'logits_state', 'window_block']],
            outputs=__fields['plot_block'],
            queue=False,
            show_progress='full'
        ).then(
        # update the range of possible values for the window
            fn=update_window_range,
            inputs=[__fields[__k] for __k in ['window_block', 'indices_state']],
            outputs=__fields['window_block'],
            queue=False,
            show_progress='hidden')
        # update the plots when the window changes
        __fields['window_block'].change(
            fn=update_human_plots,
            inputs=[__fields[__k] for __k in ['indices_state', 'logits_state', 'window_block']],
            outputs=__fields['plot_block'],
            queue=False,
            show_progress='full')
        # gradio application
        return __app

# MAIN #########################################################################

if __name__ == '__main__':
    # load the model
    __device = 'cuda' if torch.cuda.is_available() else 'cpu'
    __tokenizer = psaiops.common.tokenizer.get_tokenizer(name=MODEL, device=__device)
    __model = psaiops.common.model.get_model(name=MODEL, device=__device)
    # adapt the event handlers
    __tokenize = functools.partial(update_indices_state, tokenizer_obj=__tokenizer)
    __compute = functools.partial(update_logits_state, model_obj=__model)
    __score = functools.partial(update_human_scores, tokenizer_obj=__tokenizer)
    # the event handlers are created outside so that they can be wrapped with `spaces.GPU` if necessary
    __app = create_app(tokenize=__tokenize, compute=__compute, score=__score)
    __app.launch(theme=gradio.themes.Soft(), css=psaiops.common.style.BUTTON, share=True, debug=True)
